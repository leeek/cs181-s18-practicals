{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ModelWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper to simplify the process of\n",
    "    loading data, parameter tuning, etc\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_name, *args, debug=False, **kwargs):\n",
    "        df = pd.read_csv(csv_name)\n",
    "        self.X = self.preprocess_X(df.iloc[:, :-1])\n",
    "        \n",
    "        # when debugging only use a tiny subset of the data\n",
    "        if debug:\n",
    "            self.X = self.X[:10]\n",
    "\n",
    "        self.Y = df.iloc[:,-1]\n",
    "        \n",
    "    def preprocess_X(self, X):\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Return a list of predictions\n",
    "        and error associated with the model\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train on a subset of the data, returning\n",
    "        a model\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Builds a model\n",
    "        \"\"\"\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X, self.Y)\n",
    "        self.train(X_train, Y_train)\n",
    "        Y_pred = self.predict(X_test)\n",
    "        print (mean_squared_error(Y_pred, Y_test), \"ERROR\")\n",
    "\n",
    "\n",
    "class SKLearnModelWrapper(ModelWrapper):\n",
    "    \"\"\"\n",
    "    Specifically built for SKLearn models\n",
    "    \"\"\"\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Return the SKLearn model class\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        self.model = self.get_model()\n",
    "        assert (self.model is not None)\n",
    "        self.model.fit(X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "class CombinedModelWrapper(ModelWrapper):\n",
    "    \"\"\"\n",
    "    Combines the predictions for several models\n",
    "    MAKE SURE THAT THE DATAFRAMES ARE ORDERED\n",
    "    THE SAME WAY!!\n",
    "    \"\"\"\n",
    "    def __init__(self, models, *args, **kwargs):\n",
    "        self.models = models\n",
    "        self.X = list(zip(model.X for model in models))\n",
    "        print (self.X, \"THE XX\", np.shape(self.X))\n",
    "        self.Y = models[0].Y[:len(self.X)]\n",
    "        \n",
    "    def apply_models(self, X):\n",
    "        return [\n",
    "            [\n",
    "                model.predict(x)\n",
    "                for model, x in zip(self.models, dataset)\n",
    "            ]\n",
    "            for dataset in X\n",
    "        ]\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        X_transformed = self.apply_models(X)\n",
    "        return super(CombinedModelWrapper, self).train(X_transformed, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_transformed = self.apply_models(X)\n",
    "        return super(CombinedModelWrapper, self).predict(X_transformed)\n",
    "\n",
    "    def build_model(self):\n",
    "        for model in self.models:\n",
    "            model.build_model()\n",
    "\n",
    "        return super(CombinedModelWrapper, self).build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_wrapper import CombinedModelWrapper\n",
    "# from model_wrapper import SKLearnModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoost(SKLearnModelWrapper):\n",
    "    def get_model(self):\n",
    "        return GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=0, loss='ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "coulomb_boost = GradientBoost(\"data/coulomb_features.csv\", debug=True)\n",
    "adjacency_boost = GradientBoost(\"data/adjacency_features.csv\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedBoost(CombinedModelWrapper, SKLearnModelWrapper):\n",
    "    def get_model(self):\n",
    "        return GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=0, loss='ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(   Unnamed: 0            0           1           2           3           4  \\\n",
      "0           0  2369.249756  471.394089  379.020768  362.656456  123.887716   \n",
      "1           1   323.479177  275.202634  135.462538   79.855681   62.962204   \n",
      "2           2   451.625863  369.881915  287.156201  124.146651   85.088582   \n",
      "3           3   329.352269  268.817810  149.091524   90.978229   69.496204   \n",
      "4           4   412.512190  180.305274  102.637158   81.771576   72.008124   \n",
      "5           5   411.522206  295.886781  142.758587   85.477563   72.969304   \n",
      "6           6   403.965231  155.097606   76.964561   67.482997   60.398252   \n",
      "7           7  2377.902790  435.518733  369.542023  133.069321   79.643201   \n",
      "8           8   174.873804  103.608836   78.643335   63.071334   50.897042   \n",
      "9           9   405.898100  156.376970   76.262067   68.597427   60.322206   \n",
      "\n",
      "           5          6          7          8 ...   190  191  192  193  194  \\\n",
      "0  93.281489  64.132983  52.998261  51.351622 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "1  53.814247  44.358258  41.205047  37.427233 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "2  65.298760  51.397261  47.140238  44.858463 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "3  52.759613  49.174455  42.097262  40.551572 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "4  61.960256  50.282792  47.523480  46.460849 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "5  54.259184  47.436955  46.948359  38.861795 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "6  48.141624  41.693356  37.259066  35.224612 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "7  63.973872  57.840657  44.880942  40.439704 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "8  43.326500  42.362835  41.015617  36.141102 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "9  47.381184  40.988291  39.478808  33.801708 ...   0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   195  196  197  198  199  \n",
      "0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  \n",
      "5  0.0  0.0  0.0  0.0  0.0  \n",
      "6  0.0  0.0  0.0  0.0  0.0  \n",
      "7  0.0  0.0  0.0  0.0  0.0  \n",
      "8  0.0  0.0  0.0  0.0  0.0  \n",
      "9  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[10 rows x 201 columns],), (   Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0           0  2.535762  2.381411  2.252115  1.945637  1.671601  1.509454   \n",
      "1           1  2.579282  2.362242  2.098524  1.911152  1.597844  1.423166   \n",
      "2           2  2.625472  2.437756  2.248140  1.879916  1.688886  1.421876   \n",
      "3           3  2.627169  2.425060  2.252243  1.870211  1.724600  1.476324   \n",
      "4           4  2.643774  2.398426  2.095164  1.966626  1.917615  1.561755   \n",
      "5           5  2.570242  2.432266  2.278711  1.938567  1.711410  1.555731   \n",
      "6           6  2.543083  2.272348  2.057151  1.655055  1.476256  1.267365   \n",
      "7           7  2.612500  2.442858  2.189912  1.963629  1.777984  1.420980   \n",
      "8           8  2.532205  2.387762  2.150029  1.905390  1.582887  1.422932   \n",
      "9           9  2.616250  2.318533  2.069466  1.949008  1.623716  1.392737   \n",
      "\n",
      "          6         7         8 ...         24        25        26        27  \\\n",
      "0  1.289534  1.000000  0.882066 ...  -2.069360 -2.137573 -2.419833  0.000000   \n",
      "1  1.276116  1.081270  0.698000 ...  -2.534013  0.000000  0.000000  0.000000   \n",
      "2  1.276186  1.254660  1.000000 ...  -2.106279 -2.240733 -2.437173  0.000000   \n",
      "3  1.279376  1.177208  1.000000 ...  -2.127205 -2.218193 -2.462894  0.000000   \n",
      "4  1.305681  1.193212  1.101034 ...  -1.753248 -1.861579 -2.084842 -2.400522   \n",
      "5  1.383503  1.258730  1.186773 ...  -1.854390 -1.893235 -2.054476 -2.311560   \n",
      "6  1.161869  0.922716  0.691930 ...   0.000000  0.000000  0.000000  0.000000   \n",
      "7  1.270231  1.199566  1.168240 ...  -1.910062 -2.044125 -2.331301 -2.479698   \n",
      "8  1.255274  1.068620  0.923516 ...  -2.477725  0.000000  0.000000  0.000000   \n",
      "9  1.000000  0.961067  0.618034 ...   0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         28   29   30   31   32   33  \n",
      "0  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "4 -2.500076  0.0  0.0  0.0  0.0  0.0  \n",
      "5 -2.541541  0.0  0.0  0.0  0.0  0.0  \n",
      "6  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "7  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "8  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "9  0.000000  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[10 rows x 35 columns],)] THE XX (2, 1)\n"
     ]
    }
   ],
   "source": [
    "combined_boost = CombinedBoost([coulomb_boost, adjacency_boost], debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 201) (10000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 10000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-20cb522e95d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_boost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-87-21f5428bc214>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCombinedModelWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-21f5428bc214>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 10000]"
     ]
    }
   ],
   "source": [
    "combined_boost.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
